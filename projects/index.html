
<!--DOCTYPE HTML>

	Story by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Alyssa Pennini - Projects</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<link rel="apple-touch-icon" sizes="180x180" href="../assets/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../assets/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../assets/favicons/favicon-16x16.png">
		<link rel="manifest" href="../assets/favicons/manifest.json">
		<link rel="mask-icon" href="../assets/favicons/safari-pinned-tab.svg" color="#5bbad5">
		<meta name="theme-color" content="#ffffff">
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper" class="divided">
				
				<!-- One -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Things I've Done</h2>
						</div>
					</section>
				<!-- Two -->
					<section class="spotlight style2 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
						<div class="content">
							<h2>Classification in Medical Diagnostics</h2>
							<p><strong>Objective:</strong> The goal of this project was to implement the k-nearest neighbor algorithm and Fisher's linear discriminant on the University of Wisconsin Diagnostic Breast Cytology data set in order to classify the data as either benign or malignant as well as to assess the accuracy of each method.</p> 
							<p><strong>Data:</strong> The raw diagnostic dataset included 30 real attributes as well as 569 instances, 357 of which were labeled benign and 212 labeled as malignant.</p>
							<p><strong>Methods & Analysis:</strong> In the case of k-nearest neighbor classification, there is a general recommendation of a 70/30 split between the training and test sets, respectively. For this assignment, a two-thirds/one-third split was used due to it’s similar breakdown to the total dataset in which 62.74% of instances were classified as benign and the other 37.26% were malignant. For each of five random training sets, the 1NN, 3NN and linear discriminant analysis were applied before predicting the diagnostic classification with the test set and calculating the accuracy and error percentages. Finally, the accuracy and error rates of the five random sets were averaged to determine the final accuracy rates for comparison.</p>		
							<p><strong>Conclusion:</strong> The results of the analysis showed that, for the k-nearest neighbor algorithm, the higher the value of k, the higher the accuracy of the predictions. On the other hand, linear discriminant analysis proved to be more accurate than 1NN, though not as accurate as 3NN.</p>
						</div>
						<div class="image">
							<img src="../assets/images/bras.jpg" alt="" />
						</div>
					</section>

				<!-- Three -->
					<section class="spotlight style2 orient-left content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Predicting the 2016 US Presidential Election</h2>
							<p>Professor Allan Lichtman of American University has developed a system of predicting the winner of US Presidential elections based on 13 true or false questions he calls <a href="https://en.wikipedia.org/wiki/The_Keys_to_the_White_House"><em>The Keys to the White House</em></a>. The theory places more weight on the current performance of the political party in power than the campaigning of opposing candidates.</p>
							<p><strong>Objective:</strong> The aim of this project was to determine the accuracy of both the decision tree and k-nearest neighbor algorithms on Lichtman's "Keys to the White House" in predicting the outcome of the 2016 US Presidential election.</p>
							<p><strong>Data:</strong> Using a modified version of Lichtman's Keys, the data included 12 true or false questions for elections from 1860 to 1980. The outcomes of these elections included 17 incumbent party winners as well as 13 opposition party winners. In the case of the 2016 election, the questions were answered personally with uncertain questions being tested with both answers.</p>
							<p><strong>Methods & Analysis:</strong> With only data for 30 elections, random test sets were composed of 3 incumbent party victories and 2 opposition party victories with the rest comprising the training sets. This process was repeated for a total of 8 test and subsequent training sets. uncertainty concerning three questions which created 6 test sets with the training set consisting of the entire original dataset. For each of these sets, the decision tree algorithm was initially implemented using a minimum split of 2 before utilizing minimum splits of 3, 4 and 5. In addition, the k-nearest neighbor algorithm, with k=1 and k=3, was applied and tested for comparison purposes.</p>
							<p><strong>Conclusion:</strong> The analysis proved that the 3NN algorithm was the most accurate for the test sets as well as predicting the popular vote of the 2016 election. However, none of the methods proved worthwhile for predicting the actual winner of the election due to the formulation of the electoral college.</p>
							
							<ul class="actions vertical">
								<li><a href="reports/election.pdf" class="button">Download Report</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="../assets/images/white_house.jpg" alt="" />
						</div>
					</section>

				<!-- Four -->
					<section class="spotlight style2 orient-right content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Modeling and Predicting Mortgage Customer Retention</h2>
							<p>A bank, looking to prevent the loss of mortgage customers at the end of the 'lock-in' period, asked for an analysis of customers' personal circumstances to determine if any variables significantly influence the customer's decision to stay or leave the bank.</p>
							<p><strong>Objective:</strong> The goal of the analysis was to develop a generalized linear model that describes the given data as well as provides accurate prediction results for future use.</p>
							<p><strong>Data:</strong> The data provided by the bank include information for 399 of their customers with 23 attributes describing the personal circumstances of the customer. After removing the redundant attributes, 1 response variable and 18 explanatory variables were left, consisting of both discrete and continuous variables.</p>
							<p><strong>Methods & Analysis:</strong> Due to the binary nature of the response variable, logistic regression was utilized in this analysis with the assessment of model fit being determined by Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), McFadden’s pseudo-R-Squared, classification tables as well as residual deviance and p-value in the case of nested models.</p>
							<p>Model selection comprised of forward stepwise selection beginning with the null model which provided the initial comparison for AIC and BIC values. Successive single predictor models were created by adding each explanatory variable to the null model. Variables with models over both the minimum AIC and BIC were eliminated from further analysis. The minimum AIC and BIC for the set, as well as the maximum R-Squared and calculated accuracy percentages, are noted and used as the comparison values for the next set of models. Subsequent sets of two-predictor models were then created using all combinations of the remaining explanatory variables whereas, for three-predictor models and above, only combinations of the previous models were created when one or more common variables were present.</p>
							<p><strong>Conclusion:</strong> The analysis resulted in a model that showed a significant relationship between a customer's account status and their choice of being a branch user, a direct/telephone user, and having an agent. In other words, it is in the bank's best interests to place more importance on customers having a relationship with the bank as well as initiating specific points of contact in order to retain the most business.</p>
						
							<ul class="actions vertical">
								<li><a href="reports/bank.pdf" class="button">Download Report</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="../assets/images/houses.jpg" alt="" />
						</div>
					</section>
					
				<!-- Five -->
					<section class="spotlight style2 orient-left content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Optimizing Dilution Rates for Nonlinear Functional Response</h2>
							<p><strong>Objective:</strong> The aim of this project was to improve the efficiency and accuracy of the dilution experiments by optimizing the allocation of dilution rates. This should produce more accurate estimates for both the phytoplankton growth and microzooplankton grazing rates, especially in the case of nonlinear grazing. </p>				
							<p><strong>Data:</strong> The data used in this research was approximated from the four dilution data plots in the article <a href="doi: 10.1002/lno.10536"><em>Recovering growth and grazing rates from nonlinear dilution experiments</em></a>. The approximations resulted in four datasets, two with 12 data points each, one with 13 data points and one with 14 data points.</p>
							<p><strong>Methods & Analysis:</strong> To accomplish this, the 4th order Runge-Kutta method is used in solving the differential equation describing plankton dynamics before employing both unconstrained, for the parameters, and constrained nonlinear optimization for the allocation of dilution rates. In regards to the functional response curve, the Holling Type II is the primary curve, however, three others, Holling Type I, Ivlev and hyperbolic tangent, were also considered and compared. In addition, numerical simulation was performed using a 25% proportional level of noise across the dilution rates.</p>
							<p><strong>Conclusion:</strong> This research demonstrated that a computational approach using the 4th order Runge-Kutta method as well as constrained and unconstrained nonlinear optimization was preferential to other approximated methods, especially in the necessary examination of multiple functional response curves. The results specifically indicated that the inclusion of multiple high dilution samples (<= 0.2), with at least one very highly diluted sample (<= 0.05), provided minimal error for both the parameter estimates as well as the associated functional response curve in comparison to the known true response.</p>
						
							<ul class="actions vertical">
								<li><a href="reports/Apennini_DissertationA4.pdf" class="button">Download Report</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="https://upload.wikimedia.org/wikipedia/commons/9/99/Phytoplankton_-_the_foundation_of_the_oceanic_food_chain.jpg" alt="" />
						</div>
					</section>

				<!-- Seven -->
					<section class="wrapper style1 align-center">
						<div class="inner medium">
							<h2>Get in touch</h2>
							<form method="post" action="#">
								<div class="field half first">
									<label for="name">Name</label>
									<input type="text" name="name" id="name" value="" />
								</div>
								<div class="field half">
									<label for="email">Email</label>
									<input type="email" name="email" id="email" value="" />
								</div>
								<div class="field">
									<label for="message">Message</label>
									<textarea name="message" id="message" rows="6"></textarea>
								</div>
								<ul class="actions">
									<li><input type="submit" name="submit" id="submit" value="Send Message" /></li>
								</ul>
							</form>

						</div>
					</section>

				<!-- Footer -->
					<footer class="wrapper style1 align-center">
						<div class="inner">
							<ul class="icons">
								<li><a href="https://aspennini.github.io" class="icon style2 fa-home"><span class="label">Home</span></a></li>
								<li><a href="mailto:aspennini@gmail.com" class="icon style2 fa-envelope"><span class="label">Email</span></a></li>
								<li><a href="https://github.com/aspennini" class="icon style2 fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/alyssapennini" class="icon style2 fa-linkedin"><span class="label">LinkedIn</span></a></li>
							</ul>
							<p>&copy; Alyssa Pennini. Design: <a href="https://html5up.net">HTML5 UP</a>. Images: <a href="https://unsplash.com">Unsplash</a>.</p>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>-->
